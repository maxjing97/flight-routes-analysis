{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7ef589",
   "metadata": {},
   "source": [
    "\n",
    "# General information of the datascrapping process.\n",
    "\n",
    "Here, we get vital data for the key airports we want to scrape data from:\n",
    "\n",
    "location (coordinates, country, city), IATA code,\n",
    "\n",
    "This then allows us, using the wikipedia API to find each airport's corresponding wikipedia link and wikipedia name.\n",
    "For example JFK is encoded in wikipedia's internal database as John_F._Kennedy_International_Airport. This matches the last part of the url in the wikipedia page link for the airport:     \n",
    "https://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport\n",
    "\n",
    "For each time range:\n",
    "\n",
    "The wikipedia page's raw text can be scrapped predictiably for a list of destinations from an airport. We will encode airport destinations using iata code.\n",
    "\n",
    "We do this for each airport, generating a large csv file of airport-destination pairs for a particular time change.\n",
    "\n",
    "We will look at 2 time ranges (now(as of June 4th 11am Eastern Time), before Jan 1, 2000 UTC 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a557d",
   "metadata": {},
   "source": [
    "### Sources :\n",
    "\n",
    "\n",
    "list of top 1000 airports by traffic to scrape:\n",
    "\n",
    "https://gettocenter.com/airports/top-100-airports-in-world/1000#google_vignette  \n",
    "\n",
    "\n",
    "detailed airport database to cross reference:\n",
    "\n",
    "https://www.partow.net/miscellaneous/airportdatabase/index.html#Downloads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a698ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "# Suppress just SettingWithCopyWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4779b1bb",
   "metadata": {},
   "source": [
    "# Part 1: get basic data for the list of top 1000 airports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25fa4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load HTML from a URL or string\n",
    "url = \"https://gettocenter.com/airports/top-100-airports-in-world/1000\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find(\"table\")  \n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "with open(\"./data/top_airports_basic_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        # Extract all cells (td or th)\n",
    "        cols = row.find_all([\"td\", \"th\"])\n",
    "        # Write the row text content to CSV\n",
    "        writer.writerow([col.get_text(strip=True) for col in cols])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae1a6d",
   "metadata": {},
   "source": [
    "after replacing blank strings \"\", read in again csv file and add column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3f9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087\n",
      "989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>iata</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>estimated_pax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Hartsfield–Jackson Atlanta International Airport</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>United States</td>\n",
       "      <td>103,902,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Beijing Capital International Airport</td>\n",
       "      <td>PEK</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>95,786,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Dubai International Airport</td>\n",
       "      <td>DXB</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>88,242,099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>United States</td>\n",
       "      <td>84,557,968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>O'Hare International Airport</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>United States</td>\n",
       "      <td>79,828,183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>Heathrow Airport</td>\n",
       "      <td>LHR</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>78,014,598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>Haneda Airport</td>\n",
       "      <td>HND</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>76,476,251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>Hong Kong International Airport</td>\n",
       "      <td>HKG</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>72,665,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>Shanghai Pudong International Airport</td>\n",
       "      <td>PVG</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>China</td>\n",
       "      <td>70,001,237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>Charles de Gaulle International Airport</td>\n",
       "      <td>CDG</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>69,471,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>Amsterdam Airport Schiphol</td>\n",
       "      <td>AMS</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>68,515,425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_name iata         city  \\\n",
       "1.0   Hartsfield–Jackson Atlanta International Airport  ATL      Atlanta   \n",
       "2.0              Beijing Capital International Airport  PEK      Beijing   \n",
       "3.0                        Dubai International Airport  DXB        Dubai   \n",
       "4.0                  Los Angeles International Airport  LAX  Los Angeles   \n",
       "5.0                       O'Hare International Airport  ORD      Chicago   \n",
       "6.0                                   Heathrow Airport  LHR       London   \n",
       "7.0                                     Haneda Airport  HND        Tokyo   \n",
       "8.0                    Hong Kong International Airport  HKG    Hong Kong   \n",
       "9.0              Shanghai Pudong International Airport  PVG     Shanghai   \n",
       "10.0           Charles de Gaulle International Airport  CDG        Paris   \n",
       "11.0                        Amsterdam Airport Schiphol  AMS    Amsterdam   \n",
       "\n",
       "                   country estimated_pax  \n",
       "1.0          United States   103,902,992  \n",
       "2.0                  China    95,786,442  \n",
       "3.0   United Arab Emirates    88,242,099  \n",
       "4.0          United States    84,557,968  \n",
       "5.0          United States    79,828,183  \n",
       "6.0         United Kingdom    78,014,598  \n",
       "7.0                  Japan    76,476,251  \n",
       "8.0              Hong Kong    72,665,078  \n",
       "9.0                  China    70,001,237  \n",
       "10.0                France    69,471,442  \n",
       "11.0           Netherlands    68,515,425  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/top_airports_basic_data.csv\", names=[\"full_name\", \"iata\", \"city\", \"country\", \"estimated_pax\"])\n",
    "print(len(data))\n",
    "data=data.dropna()\n",
    "print(len(data))\n",
    "data.head(n=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402836c",
   "metadata": {},
   "source": [
    "we now have obtain basic information for the top airports the the world. save the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885e5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./data/top_airports_basic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03d3e2",
   "metadata": {},
   "source": [
    "#  Part 2:\n",
    "Get wikipedia urls and for each iata code by using search api in wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e434bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Hartsfield–Jackson_Atlanta_International_Airport\n",
      "https://en.wikipedia.org/wiki/Gobernador_Edgardo_Castello_Airport\n"
     ]
    }
   ],
   "source": [
    "#testing a function\n",
    "def get_wikipedia_url_from_name(name):\n",
    "    \"\"\"Search Wikipedia using IATA code and return the best-matching article title.\"\"\"\n",
    "    search_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": f\"{name}\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(search_url, params=params)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        raw_name = data['query']['search'][0]['title'] \n",
    "        raw_name = raw_name.replace(\" \", \"_\") #replace the raw name spaces with _\n",
    "\n",
    "        return \"https://en.wikipedia.org/wiki/\"+raw_name #format for english wiki\n",
    "    except (KeyError, IndexError):\n",
    "        return None\n",
    "    \n",
    "print(get_wikipedia_url_from_name(\"Hartsfield–Jackson Atlanta International Airport\")) #popular airport\n",
    "print(get_wikipedia_url_from_name(\"Gobernador Castello Airport\")) #more obscure airport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c190eaf8",
   "metadata": {},
   "source": [
    "now, run for all airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a088ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/top_airports_basic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbc5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current index: 0\n",
      "current index: 1\n",
      "current index: 2\n",
      "current index: 3\n",
      "current index: 4\n",
      "current index: 5\n",
      "current index: 6\n",
      "current index: 7\n",
      "current index: 8\n",
      "current index: 9\n",
      "current index: 10\n",
      "current index: 11\n",
      "current index: 12\n",
      "current index: 13\n",
      "current index: 14\n",
      "current index: 15\n",
      "current index: 16\n",
      "current index: 17\n",
      "current index: 18\n",
      "current index: 19\n",
      "current index: 20\n",
      "current index: 21\n",
      "current index: 22\n",
      "current index: 23\n",
      "current index: 24\n",
      "current index: 25\n",
      "current index: 26\n",
      "current index: 27\n",
      "current index: 28\n",
      "current index: 29\n",
      "current index: 30\n",
      "current index: 31\n",
      "current index: 32\n",
      "current index: 33\n",
      "current index: 34\n",
      "current index: 35\n",
      "current index: 36\n",
      "current index: 37\n",
      "current index: 38\n",
      "current index: 39\n",
      "current index: 40\n",
      "current index: 41\n",
      "current index: 42\n",
      "current index: 43\n",
      "current index: 44\n",
      "current index: 45\n",
      "current index: 46\n",
      "current index: 47\n",
      "current index: 48\n",
      "current index: 49\n",
      "current index: 50\n",
      "current index: 51\n",
      "current index: 52\n",
      "current index: 53\n",
      "current index: 54\n",
      "current index: 55\n",
      "current index: 56\n",
      "current index: 57\n",
      "current index: 58\n",
      "current index: 59\n",
      "current index: 60\n",
      "current index: 61\n",
      "current index: 62\n",
      "current index: 63\n",
      "current index: 64\n",
      "current index: 65\n",
      "current index: 66\n",
      "current index: 67\n",
      "current index: 68\n",
      "current index: 69\n",
      "current index: 70\n",
      "current index: 71\n",
      "current index: 72\n",
      "current index: 73\n",
      "current index: 74\n",
      "current index: 75\n",
      "current index: 76\n",
      "current index: 77\n",
      "current index: 78\n",
      "current index: 79\n",
      "current index: 80\n",
      "current index: 81\n",
      "current index: 82\n",
      "current index: 83\n",
      "current index: 84\n",
      "current index: 85\n",
      "current index: 86\n",
      "current index: 87\n",
      "current index: 88\n",
      "current index: 89\n",
      "current index: 90\n",
      "current index: 91\n",
      "current index: 92\n",
      "current index: 93\n",
      "current index: 94\n",
      "current index: 95\n",
      "current index: 96\n",
      "current index: 97\n",
      "current index: 98\n",
      "current index: 99\n",
      "current index: 100\n",
      "current index: 101\n",
      "current index: 102\n",
      "current index: 103\n",
      "current index: 104\n",
      "current index: 105\n",
      "current index: 106\n",
      "current index: 107\n",
      "current index: 108\n",
      "current index: 109\n",
      "current index: 110\n",
      "current index: 111\n",
      "current index: 112\n",
      "current index: 113\n",
      "current index: 114\n",
      "current index: 115\n",
      "current index: 116\n",
      "current index: 117\n",
      "current index: 118\n",
      "current index: 119\n",
      "current index: 120\n",
      "current index: 121\n",
      "current index: 122\n",
      "current index: 123\n",
      "current index: 124\n",
      "current index: 125\n",
      "current index: 126\n",
      "current index: 127\n",
      "current index: 128\n",
      "current index: 129\n",
      "current index: 130\n",
      "current index: 131\n",
      "current index: 132\n",
      "current index: 133\n",
      "current index: 134\n",
      "current index: 135\n",
      "current index: 136\n",
      "current index: 137\n",
      "current index: 138\n",
      "current index: 139\n",
      "current index: 140\n",
      "current index: 141\n",
      "current index: 142\n",
      "current index: 143\n",
      "current index: 144\n",
      "current index: 145\n",
      "current index: 146\n",
      "current index: 147\n",
      "current index: 148\n",
      "current index: 149\n",
      "current index: 150\n",
      "current index: 151\n",
      "current index: 152\n",
      "current index: 153\n",
      "current index: 154\n",
      "current index: 155\n",
      "current index: 156\n",
      "current index: 157\n",
      "current index: 158\n",
      "current index: 159\n",
      "current index: 160\n",
      "current index: 161\n",
      "current index: 162\n",
      "current index: 163\n",
      "current index: 164\n",
      "current index: 165\n",
      "current index: 166\n",
      "current index: 167\n",
      "current index: 168\n",
      "current index: 169\n",
      "current index: 170\n",
      "current index: 171\n",
      "current index: 172\n",
      "current index: 173\n",
      "current index: 174\n",
      "current index: 175\n",
      "current index: 176\n",
      "current index: 177\n",
      "current index: 178\n",
      "current index: 179\n",
      "current index: 180\n",
      "current index: 181\n",
      "current index: 182\n",
      "current index: 183\n",
      "current index: 184\n",
      "current index: 185\n",
      "current index: 186\n",
      "current index: 187\n",
      "current index: 188\n",
      "current index: 189\n",
      "current index: 190\n",
      "current index: 191\n",
      "current index: 192\n",
      "current index: 193\n",
      "current index: 194\n",
      "current index: 195\n",
      "current index: 196\n",
      "current index: 197\n",
      "current index: 198\n",
      "current index: 199\n",
      "current index: 200\n",
      "current index: 201\n",
      "current index: 202\n",
      "current index: 203\n",
      "current index: 204\n",
      "current index: 205\n",
      "current index: 206\n",
      "current index: 207\n",
      "current index: 208\n",
      "current index: 209\n",
      "current index: 210\n",
      "current index: 211\n",
      "current index: 212\n",
      "current index: 213\n",
      "current index: 214\n",
      "current index: 215\n",
      "current index: 216\n",
      "current index: 217\n",
      "current index: 218\n",
      "current index: 219\n",
      "current index: 220\n",
      "current index: 221\n",
      "current index: 222\n",
      "current index: 223\n",
      "current index: 224\n",
      "current index: 225\n",
      "current index: 226\n",
      "current index: 227\n",
      "current index: 228\n",
      "current index: 229\n",
      "current index: 230\n",
      "current index: 231\n",
      "current index: 232\n",
      "current index: 233\n",
      "current index: 234\n",
      "current index: 235\n",
      "current index: 236\n",
      "current index: 237\n",
      "current index: 238\n",
      "current index: 239\n",
      "current index: 240\n",
      "current index: 241\n",
      "current index: 242\n",
      "current index: 243\n",
      "current index: 244\n",
      "current index: 245\n",
      "current index: 246\n",
      "current index: 247\n",
      "current index: 248\n",
      "current index: 249\n",
      "current index: 250\n",
      "current index: 251\n",
      "current index: 252\n",
      "current index: 253\n",
      "current index: 254\n",
      "current index: 255\n",
      "current index: 256\n",
      "current index: 257\n",
      "current index: 258\n",
      "current index: 259\n",
      "current index: 260\n",
      "current index: 261\n",
      "current index: 262\n",
      "current index: 263\n",
      "current index: 264\n",
      "current index: 265\n",
      "current index: 266\n",
      "current index: 267\n",
      "current index: 268\n",
      "current index: 269\n",
      "current index: 270\n",
      "current index: 271\n",
      "current index: 272\n",
      "current index: 273\n",
      "current index: 274\n",
      "current index: 275\n",
      "current index: 276\n",
      "current index: 277\n",
      "current index: 278\n",
      "current index: 279\n",
      "current index: 280\n",
      "current index: 281\n",
      "current index: 282\n",
      "current index: 283\n",
      "current index: 284\n",
      "current index: 285\n",
      "current index: 286\n"
     ]
    }
   ],
   "source": [
    "data[\"wiki_url\"] =None #add column\n",
    "for index, row in data.iterrows():\n",
    "    try:\n",
    "        print(\"current index:\", index)\n",
    "        name = row[\"full_name\"]\n",
    "        url = get_wikipedia_url_from_name(name)\n",
    "        data[\"wiki_url\"][index] = url\n",
    "    except:\n",
    "        data[\"wiki_url\"][index] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43366a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(n=989)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac4ede",
   "metadata": {},
   "source": [
    "finding number of null entries in the wiki_url column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeccba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of null entries: {data['wiki_url'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee562f5",
   "metadata": {},
   "source": [
    "find the null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['wiki_url'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613333f",
   "metadata": {},
   "source": [
    "saving the updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./data/top_airports_basic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde77550",
   "metadata": {},
   "source": [
    "# Part 3:\n",
    "\n",
    "Try to get wikipedia airport names with underscores to make querying easier, and testing a script to get a list of destinations from a wikipedia article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc22e2e",
   "metadata": {},
   "source": [
    "### getting wikipedia name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6eb00d",
   "metadata": {},
   "source": [
    "Populating wikipedia names in our top_airports_basic_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066aea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the wikipedia name based on the url, is simply found as:\n",
    "print(\"name:\", \"https://en.wikipedia.org/wiki/Victoria_International_Airport\".split(\"https://en.wikipedia.org/wiki/\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d597f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/top_airports_basic_data.csv\")\n",
    "data.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"wiki_name\"] = None \n",
    "wiki_names = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    url = str(row[\"wiki_url\"])\n",
    "    wiki_names.append(url.split(\"https://en.wikipedia.org/wiki/\")[1])\n",
    "    \n",
    "data[\"wiki_name\"] = wiki_names\n",
    "#overwrite\n",
    "data.to_csv(\"./data/top_airports_basic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8373de4",
   "metadata": {},
   "source": [
    "# Part 4 : Transition into getting routes data (in the other jupyter notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0c64b",
   "metadata": {},
   "source": [
    "### testing script to get raw text from a wikipedia page and get a list of destination-tuples for the current destinations listed in wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract text between two found substrings\n",
    "def extract_between(text, start, end):\n",
    "    start_idx = text.find(start)\n",
    "    if start_idx == -1:\n",
    "        return \"\" #return empty string\n",
    "    start_idx += len(start)\n",
    "    end_idx = text.find(end, start_idx)\n",
    "    if end_idx == -1:\n",
    "        return \"\"\n",
    "    return text[start_idx:end_idx]\n",
    "#function to get iata code from wikipedia name\n",
    "def get_iata_code(iata,ref_data=pd.read_csv(\"./data/top_airports_basic_data.csv\")):\n",
    "    matched = ref_data[ref_data[\"wiki_name\"]==iata].iloc[0]\n",
    "    return matched[\"iata\"]\n",
    "    \n",
    "\n",
    "def get_destinations(iata_source, wiki_name):\n",
    "    search_url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&action=raw\"\n",
    "    response = requests.get(search_url)\n",
    "    full_text = response.text\n",
    "    #get to the passenger destinations section marked by a predictiable substrings ()\n",
    "    # Call both and choose the first non-None result\n",
    "    destinations_text = extract_between(full_text, \"=== Passenger ===\", \"==\") or extract_between(full_text, \"===Passenger===\", \"==\")\n",
    "    destinations_list = destinations_text.split(\"<!-- -->\")#split predictably\n",
    "    \n",
    "    return_list = [] #return a list of destination of tuple of the form (iata_source, starting_wiki_name, dest_wikipedia_name,airline, isSeasonal)\n",
    "    #ignore the first part, since that is some disclaimer\n",
    "    for i in range(1, len(destinations_list)):\n",
    "        airlineDest = destinations_list[i]#we get a list relating to airlines and their list of destinations\n",
    "        #get information before and the seasonal destination section (if present)\n",
    "        beforeSeasonal = \"\"\n",
    "        afterSeasonal = None\n",
    "        if \"'''Seasonal:'''\" in airlineDest:\n",
    "            seasonalSplit = airlineDest.split(\"'''Seasonal:'''\")\n",
    "            beforeSeasonal = seasonalSplit[0]\n",
    "            afterSeasonal = seasonalSplit[1]\n",
    "        else: \n",
    "            beforeSeasonal = airlineDest \n",
    "        \n",
    "        #get the airline based on a predictable pattern (in the first element)\n",
    "        beforeSeasonalsplit = beforeSeasonal.split(\",\") #split based on commas\n",
    "        airline_firstdest = beforeSeasonalsplit[0].split(\" | [[\")  #split between the airline and first destination\n",
    "        airline = str(airline_firstdest[0]) #extract the airline\n",
    "        airline = extract_between(airline,\"[[\",\"]]\") #remove the [[]]\n",
    "        #do a final split just in case (even if | is not found), [0] selects the current string\n",
    "        firstdest = \"\"  #get first destination (assuming not seasonal) \n",
    "        if len(airline_firstdest) == 2:\n",
    "            destination = airline_firstdest[1].split(\"|\")[0].strip()\n",
    "            destination_wiki_name = destination.replace(\" \", \"_\") #replace destination to get the destination iata_code\n",
    "            return_list.append((iata_source,wiki_name,destination_wiki_name,airline,False )) #(iata_source, starting_wiki_name, dest_wikipedia_name,airline, isSeasonal)\n",
    "        #loop thorugh the rest of the comma list for the before seasonal split if possible \n",
    "        for i in range(1, len(beforeSeasonalsplit)):\n",
    "            destination = beforeSeasonalsplit[i]\n",
    "            extracted_destination = extract_between(destination,\"[[\",\"]]\")\n",
    "            if (extracted_destination!=\"\"): #assuming \n",
    "                destination_wiki_name = extracted_destination.split(\"|\")[0].strip()\n",
    "                destination_wiki_name = destination_wiki_name.replace(\" \", \"_\")\n",
    "                return_list.append((iata_source,wiki_name,destination_wiki_name,airline,False )) #(iata_source, starting_wiki_name, dest_wikipedia_name,airline, isSeasonal)\n",
    "        #loop through the seasonal destinations list if the current airline has it\n",
    "        if (afterSeasonal):\n",
    "            afterSeasonalSplit = afterSeasonal.split(\",\")\n",
    "            for i in range(0, len(afterSeasonalSplit)):\n",
    "                destination = afterSeasonalSplit[i]\n",
    "                extracted_destination = extract_between(destination,\"[[\",\"]]\")\n",
    "                if (extracted_destination!=\"\"): #assuming \n",
    "                    destination_wiki_name = extracted_destination.split(\"|\")[0].strip()\n",
    "                    destination_wiki_name = destination_wiki_name.replace(\" \", \"_\")\n",
    "                    return_list.append((iata_source,wiki_name,destination_wiki_name,airline,True )) #(iata_source, starting_wiki_name, dest_wikipedia_name,airline, isSeasonal)\n",
    "            \n",
    "    return return_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891215e",
   "metadata": {},
   "source": [
    "testing on JFK airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50252ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_destinations(\"JFK\",\"John_F._Kennedy_International_Airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_destinations(\"PAP\",\"Toussaint_Louverture_International_Airport\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
