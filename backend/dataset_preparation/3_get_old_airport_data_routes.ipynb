{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7ebb2-a56d-482c-89cb-5a9338cd6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# Suppress just SettingWithCopyWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.ChainedAssignmentError)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "pd.options.mode.chained_assignment = None  # Disable the warning\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bb83ef-5684-4ec3-8130-3ca4e482fc2e",
   "metadata": {},
   "source": [
    "# Part 1: Get most recent wikipedia urls ids for airports before 2020, and 2022\n",
    "\n",
    "This will help us analyze covid recovery route trends. Additionally, in the process we create a detailed dataset of current routes. We first check for redirects in the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redirectCheck(wiki_name):\n",
    "    url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&action=raw\"\n",
    "    response = requests.get(url)\n",
    "    #find the text between\n",
    "    text = response.text\n",
    "\n",
    "    #check for redirect\n",
    "    check_text = text.split(\"[[\")[0] #get section between [[\n",
    "    check_text = check_text.lower()\n",
    "    #if the text is clearly too long (>10 lines, there is clearly no redirect)\n",
    "    lines = text.splitlines()\n",
    "    number_of_lines = len(lines)\n",
    "    if number_of_lines > 10:\n",
    "        return wiki_name\n",
    "\n",
    "    if (\"redirect\" in check_text):\n",
    "        #get the text in between [[]]\n",
    "        redirect = text.split(\"]]\")[0]\n",
    "        #if the text does not contain a key #, we reject\n",
    "        if \"#\" not in check_text:\n",
    "            return wiki_name\n",
    "        redirect = redirect.split(\"[[\")[1]\n",
    "        redirect = redirect.replace(\" \", \"_\") #replace spaces\n",
    "        print(\"redirect found:\", redirect)\n",
    "        return redirect\n",
    "    else:\n",
    "        return wiki_name #return the same name back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirectCheck(\"Beijing_Capital_International_Airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirectCheck(\"Malacca_International_Airport\")\n",
    "redirectCheck(\"Sultan_Muhammad_Salahuddin_Airport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4275fa9e",
   "metadata": {},
   "source": [
    "Running redirects code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = pd.read_csv(\"./data/current_source_airports.csv\", encoding='utf-8')\n",
    "ref_data[\"redirects\"] = \"\" #add columns for directs \n",
    "for index, row in ref_data.iterrows():\n",
    "    iata = row[\"IATA\"]\n",
    "    wikiname = row[\"wiki_name\"]\n",
    "    print(\"reparing index:\", index)\n",
    "    val = redirectCheck(wikiname)\n",
    "    #add to redirects just in case, the original wikiname is different\n",
    "    if val != wikiname:\n",
    "        ref_data.at[index, \"redirects\"] = val\n",
    "#write to the new csv about the details of the airport\n",
    "ref_data.to_csv(\"./data/current_source_airports_details.csv\", encoding='utf-8', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb469a14-62d3-4110-89b0-915ce01bf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find version code before a certain formated date \n",
    "\n",
    "def get_oldid_before(title, date):\n",
    "    \"\"\"Get the revision ID (oldid) of the latest version before a given date.\"\"\"\n",
    "    api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": title,\n",
    "        \"rvlimit\": 1,\n",
    "        \"rvstart\": date,\n",
    "        \"rvdir\": \"older\",\n",
    "        \"rvprop\": \"ids\",\n",
    "        \"formatversion\": 2\n",
    "    }\n",
    "\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    try:\n",
    "        return str(data['query']['pages'][0]['revisions'][0]['revid'])\n",
    "    except (KeyError, IndexError):\n",
    "        return \"\"\n",
    "\n",
    "# Example usage\n",
    "id = get_oldid_before(\"John_F._Kennedy_International_Airport\", \"2020-01-01T00:00:00Z\")\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0ea10-6b88-4afc-a2d7-83a60d99180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the current routes airports source detailed data\n",
    "ref_data = pd.read_csv(\"./data/current_source_airports_details.csv\", encoding='utf-8')\n",
    "ref_data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ac48a",
   "metadata": {},
   "source": [
    "checking to see if it is possible to check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18115f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = ref_data.iloc[0][\"redirects\"]\n",
    "print(pd.isna(test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf424a81-6e83-4eeb-ae56-842ccf50a060",
   "metadata": {},
   "source": [
    "iterate to find old ids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a76277-0987-4092-90aa-b504133c37ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref_data[\"pre2020_ids\"] = None\n",
    "ref_data[\"pre2022_ids\"] = None\n",
    "pre2020_ids = []\n",
    "pre2022_ids = []\n",
    "for index, row in ref_data.iterrows():\n",
    "    print(index)\n",
    "    wiki_name = row[\"wiki_name\"]\n",
    "    #check for redirects\n",
    "    redirect = row[\"redirects\"]\n",
    "    if (pd.isna(redirect) == False): #if there is an redirect, use it\n",
    "        wiki_name = redirect\n",
    "        print(\"redirect used:\",wiki_name)\n",
    "    id1 = get_oldid_before(wiki_name, \"2020-01-01T00:00:00Z\")\n",
    "    pre2020_ids.append(id1)\n",
    "    id2 = get_oldid_before(wiki_name, \"2022-01-01T00:00:00Z\")\n",
    "    pre2022_ids.append(id2)\n",
    "ref_data[\"pre2020_ids\"] = pre2020_ids\n",
    "ref_data[\"pre2022_ids\"] = pre2022_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba8481-d421-4a53-802d-a3b2c701ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa93a6-568c-4ae8-9461-219feece2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data.to_csv(\"./data/current_source_airports_details.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a0b20-2689-4c9e-aa9e-523312ee5c80",
   "metadata": {},
   "source": [
    "checking both new columns have all non - None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c08978-a6cd-4382-9c49-e2c3f3b4eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = pd.read_csv(\"./data/current_source_airports_details.csv\")\n",
    "print( len(ref_data[ref_data[\"pre2020_ids\"].isnull()])  )\n",
    "print( len(ref_data[ref_data[\"pre2022_ids\"].isnull()])  )\n",
    "\n",
    "print( len(ref_data[ref_data[\"pre2020_ids\"]==\"\"])  )\n",
    "print( len(ref_data[ref_data[\"pre2022_ids\"]==\"\"])  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046db3c-b53d-4c0d-ba0d-ca1c1af3a786",
   "metadata": {},
   "source": [
    "checks passed, done with part 1. Keep in mind that during routes generation, if an entry has an redirect, we use that "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447747c",
   "metadata": {},
   "source": [
    "# Part 2: Route generation for 2020\n",
    "\n",
    "Additionally, improvements to current_source_airports data, new modified data for exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef31047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_destinations(iata_source, article_id, wiki_name, path_write):\n",
    "    file = open(path_write, \"a\") #file to append to\n",
    "    \n",
    "    url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&oldid={article_id}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #find the related destination table\n",
    "    # Case-insensitive string match\n",
    "    heading = soup.find(\"h2\", string=re.compile(r\"destination\", re.IGNORECASE))\n",
    "    #check text in heading\n",
    "    heading_text =  heading.get_text()\n",
    "    if  \"former\" in heading_text or \"Former\" in heading_text: #if either text is found, abort the function. This indicate the airport is no longer in service\n",
    "        file.close() #close\n",
    "        return\n",
    "        \n",
    "    \n",
    "    table = heading.find_next(\"table\") \n",
    "    while ('wikitable' not in table.get(\"class\")): #find the next table matching a predictable class, if one has not been found\n",
    "        table = table.find_next(\"table\") \n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    \n",
    "    for i in range(1,len(rows)): #exclude the first row\n",
    "        row = rows[i]\n",
    "        # Extract all cells (td or th)\n",
    "        cols = row.find_all([\"td\", \"th\"])\n",
    "        # Write the row text content to CSV\n",
    "        #first column is the airline\n",
    "        airline = cols[0].get_text(strip=True)\n",
    "        #get the list of destinations in the 2nd  \n",
    "        destinations = cols[1]\n",
    "        isSeasonal = 0 #iterate over subcomponents (seasonal always comes last, so set is seasonal to be false for now)\n",
    "        for child in destinations.children: \n",
    "            #anchor components are the only destinations\n",
    "            if (child.name == \"a\"):\n",
    "                dest_name = child.get('title') #the title is the official wikipedia airport name (without _ in place of spaces)\n",
    "                dest_name = dest_name.replace(\" \", \"_\") \n",
    "                output = f\"\\\"{iata_source}\\\",\\\"{wiki_name}\\\",\\\"{dest_name}\\\",\\\"{airline}\\\",\\\"{isSeasonal}\\\"\\n\" #final output to append to the file\n",
    "                file.write(output)#write file\n",
    "            elif ((child.name == \"b\") and (child.text == \"Seasonal:\")):\n",
    "                isSeasonal = 1 #get seasonal to be 1 for future destinations\n",
    "    file.close() #close\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1bbc9",
   "metadata": {},
   "source": [
    "get reference, airport lists for both years (from the detailed airport list earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/current_source_airports_details.csv\")\n",
    "print(len(data))\n",
    "data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac2ac10",
   "metadata": {},
   "source": [
    "checking if it is possible to check for nulls (to know when to use the redirect version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = data.iloc[0][\"redirects\"]\n",
    "print(pd.isna(test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02592333",
   "metadata": {},
   "source": [
    "Start files to start route data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc66b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_append_path = \"./data/pre2020_routes.csv\"\n",
    "f = open(file_append_path, \"w\")\n",
    "f.write(\"iata_source,starting_wiki_name,dest_wikipedia_name,airline,isSeasonal\\n\") \n",
    "f.close() #add column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b348f5",
   "metadata": {},
   "source": [
    "Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in data.iterrows():\n",
    "    print(\"airport index:\", index)\n",
    "    wikiname = row[\"wiki_name\"]\n",
    "    #check for redirects \n",
    "    redirect = row[\"redirects\"]\n",
    "    if (pd.isna(redirect) == False): \n",
    "        wikiname = redirect\n",
    "    #get the id for the year\n",
    "    id = row[\"pre2020_ids\"]\n",
    "    code = row[\"IATA\"]\n",
    "    try:\n",
    "        get_destinations(code,id,wikiname,file_append_path)\n",
    "    except:\n",
    "        print(f\"failed airport:{wikiname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_append_path, encoding='utf-8') #for windows\n",
    "data.to_csv(file_append_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294b021",
   "metadata": {},
   "source": [
    "### locating the missing airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = pd.read_csv(\"./data/current_source_airports_details.csv\") #get current airports \n",
    "all_airports = ref_data[\"IATA\"]\n",
    "print(\"number of total airports:\", len(all_airports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find missing current airports\n",
    "curr_airports = pd.read_csv(file_append_path, encoding='utf-8') #for windows\n",
    "curr_airports = curr_airports[\"iata_source\"].unique()\n",
    "print(\"number of airports currently in routes data:\", len(curr_airports))\n",
    "\n",
    "#find missing airports by set difference\n",
    "missing_airports = set(all_airports) - set(curr_airports)\n",
    "print(\"number of missing airports:\", len(missing_airports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d160a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_airports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06340187",
   "metadata": {},
   "source": [
    "Most of these airports did not exist back then or good wikipedia links from back then, with the exceptions of:\n",
    "\n",
    "ITM, TAO These are all relatively small airports. We define a function to manually add entries if a valid wikipedia article is found, by making the exact old article link be posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_routes_exact(iata_source, link, path_write, match=\"destination\"):\n",
    "    file = open(path_write, \"a\") #file to append to\n",
    "    \n",
    "    url = link\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #find the related destination table\n",
    "    # Case-insensitive string match\n",
    "    find = match\n",
    "    heading = soup.find(string=re.compile(r\"({})\".format(find), re.IGNORECASE))\n",
    "    #check text in heading\n",
    "    heading_text =  heading.get_text()\n",
    "    if  \"former\" in heading_text or \"Former\" in heading_text: #if either text is found, abort the function. This indicate the airport is no longer in service\n",
    "        file.close() #close\n",
    "        return\n",
    "        \n",
    "    \n",
    "    table = heading.find_next(\"table\") \n",
    "    rows = table.find_all(\"tr\")\n",
    "    #find wikiname by splitting \n",
    "    wiki_name = link.split(\"title=\")[1]\n",
    "    wiki_name = wiki_name.split(\"&\")[0]\n",
    "    for i in range(1,len(rows)): #exclude the first row\n",
    "        row = rows[i]\n",
    "        # Extract all cells (td or th)\n",
    "        cols = row.find_all([\"td\", \"th\"])\n",
    "        # Write the row text content to CSV\n",
    "        #first column is the airline\n",
    "        airline = cols[0].get_text(strip=True)\n",
    "        #get the list of destinations in the 2nd  \n",
    "        destinations = cols[1]\n",
    "        isSeasonal = 0 #iterate over subcomponents (seasonal always comes last, so set is seasonal to be false for now)\n",
    "        for child in destinations.children: \n",
    "            #anchor components are the only destinations\n",
    "            if (child.name == \"a\"):\n",
    "                dest_name = child.get('title') #the title is the official wikipedia airport name (without _ in place of spaces)\n",
    "                dest_name = dest_name.replace(\" \", \"_\") \n",
    "                output = f\"\\\"{iata_source}\\\",\\\"{wiki_name}\\\",\\\"{dest_name}\\\",\\\"{airline}\\\",\\\"{isSeasonal}\\\"\\n\" #final output to append to the file\n",
    "                file.write(output)#write file\n",
    "            elif ((child.name == \"b\") and (child.text == \"Seasonal:\")):\n",
    "                isSeasonal = 1 #get seasonal to be 1 for future destinations\n",
    "    file.close() #close\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48313e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair for FRS\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Mundo_Maya_International_Airport&oldid=933223161\"\n",
    "add_routes_exact(\"FRS\",link=found_link,path_write=file_append_path, match=\"airlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24218d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair for HIN\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Sacheon_Airport&oldid=1265903527\"\n",
    "add_routes_exact(\"HIN\",link=found_link,path_write=file_append_path, match=\"airlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8484b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSR did not exist back then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair for ITM\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Itami_Airport&oldid=929306656\"\n",
    "add_routes_exact(\"ITM\",link=found_link,path_write=file_append_path, match=\" terminal is planned to be extensively renovated by August 2020 to include a new pier for additional aircraft,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair for ROT\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Rotorua_Airport&oldid=996409149#Airlines_and_destinations\"\n",
    "add_routes_exact(\"ROT\",link=found_link,path_write=file_append_path, match=\"destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAO with the current name, using the old airport name, which was also in a differnt location\n",
    "found_link =  \"https://en.wikipedia.org/w/index.php?title=Qingdao_Liuting_International_Airport&oldid=992291152\"\n",
    "add_routes_exact(\"TAO\",link=found_link,path_write=file_append_path, match=\"destinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4509ddbc",
   "metadata": {},
   "source": [
    "# part 3: 2022 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357367c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_destinations(iata_source, article_id, wiki_name, path_write):\n",
    "    file = open(path_write, \"a\") #file to append to\n",
    "    \n",
    "    url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&oldid={article_id}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #find the related destination table\n",
    "    # Case-insensitive string match\n",
    "    heading = soup.find(\"h2\", string=re.compile(r\"destination\", re.IGNORECASE))\n",
    "    #check text in heading\n",
    "    heading_text =  heading.get_text()\n",
    "    if  \"former\" in heading_text or \"Former\" in heading_text: #if either text is found, abort the function. This indicate the airport is no longer in service\n",
    "        file.close() #close\n",
    "        return\n",
    "        \n",
    "    \n",
    "    table = heading.find_next(\"table\") \n",
    "    while ('wikitable' not in table.get(\"class\")): #find the next table matching a predictable class, if one has not been found\n",
    "        table = table.find_next(\"table\") \n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    \n",
    "    for i in range(1,len(rows)): #exclude the first row\n",
    "        row = rows[i]\n",
    "        # Extract all cells (td or th)\n",
    "        cols = row.find_all([\"td\", \"th\"])\n",
    "        # Write the row text content to CSV\n",
    "        #first column is the airline\n",
    "        airline = cols[0].get_text(strip=True)\n",
    "        #get the list of destinations in the 2nd  \n",
    "        destinations = cols[1]\n",
    "        isSeasonal = 0 #iterate over subcomponents (seasonal always comes last, so set is seasonal to be false for now)\n",
    "        for child in destinations.children: \n",
    "            #anchor components are the only destinations\n",
    "            if (child.name == \"a\"):\n",
    "                dest_name = child.get('title') #the title is the official wikipedia airport name (without _ in place of spaces)\n",
    "                dest_name = dest_name.replace(\" \", \"_\") \n",
    "                output = f\"\\\"{iata_source}\\\",\\\"{wiki_name}\\\",\\\"{dest_name}\\\",\\\"{airline}\\\",\\\"{isSeasonal}\\\"\\n\" #final output to append to the file\n",
    "                file.write(output)#write file\n",
    "            elif ((child.name == \"b\") and (child.text == \"Seasonal:\")):\n",
    "                isSeasonal = 1 #get seasonal to be 1 for future destinations\n",
    "    file.close() #close\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_append_path = \"./data/pre2022_routes.csv\"\n",
    "f = open(file_append_path, \"w\")\n",
    "f.write(\"iata_source,starting_wiki_name,dest_wikipedia_name,airline,isSeasonal\\n\") \n",
    "f.close() #add column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bdfaa0",
   "metadata": {},
   "source": [
    "Getting reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427416a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/current_source_airports_details.csv\")\n",
    "print(len(data))\n",
    "data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e78b8",
   "metadata": {},
   "source": [
    "Looping through to try to add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e839968",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    print(\"airport index:\", index)\n",
    "    wikiname = row[\"wiki_name\"]\n",
    "    #check for redirects \n",
    "    redirect = row[\"redirects\"]\n",
    "    if (pd.isna(redirect) == False): \n",
    "        wikiname = redirect\n",
    "    #get the id for the year\n",
    "    id = row[\"pre2022_ids\"]\n",
    "    code = row[\"IATA\"]\n",
    "    try:\n",
    "        get_destinations(code,id,wikiname,file_append_path)\n",
    "    except:\n",
    "        print(f\"failed airport:{wikiname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c722c",
   "metadata": {},
   "source": [
    "Find missing airports, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = pd.read_csv(\"./data/current_source_airports_details.csv\") #get current airports \n",
    "all_airports = ref_data[\"IATA\"]\n",
    "print(\"number of total airports:\", len(all_airports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf82027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find missing current airports\n",
    "curr_airports = pd.read_csv(file_append_path, encoding='utf-8') #for windows\n",
    "curr_airports = curr_airports[\"iata_source\"].unique()\n",
    "print(\"number of airports currently in routes data:\", len(curr_airports))\n",
    "\n",
    "#find missing airports by set difference\n",
    "missing_airports = set(all_airports) - set(curr_airports)\n",
    "print(\"number of missing airports:\", len(missing_airports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_airports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ccfc5e",
   "metadata": {},
   "source": [
    "add missing airport information, using a similar detailed repair function, but more exact and starting the specific table used for destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_to_table(iata_source, link, path_write, match=\"destination\"):\n",
    "    file = open(path_write, \"a\") #file to append to\n",
    "    print(\"trying to find:\")\n",
    "    url = link\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    \n",
    "    table = soup.find('table', class_='wikitable')\n",
    "    print(type(table))\n",
    "    rows = table.find_all(\"tr\")\n",
    "    #find wikiname by splitting \n",
    "    wiki_name = link.split(\"title=\")[1]\n",
    "    wiki_name = wiki_name.split(\"&\")[0]\n",
    "    for i in range(1,len(rows)): #exclude the first row\n",
    "        row = rows[i]\n",
    "        # Extract all cells (td or th)\n",
    "        cols = row.find_all([\"td\", \"th\"])\n",
    "        # Write the row text content to CSV\n",
    "        #first column is the airline\n",
    "        airline = cols[0].get_text(strip=True)\n",
    "        #get the list of destinations in the 2nd  \n",
    "        destinations = cols[1]\n",
    "        isSeasonal = 0 #iterate over subcomponents (seasonal always comes last, so set is seasonal to be false for now)\n",
    "        for child in destinations.children: \n",
    "            #anchor components are the only destinations\n",
    "            if (child.name == \"a\"):\n",
    "                dest_name = child.get('title') #the title is the official wikipedia airport name (without _ in place of spaces)\n",
    "                dest_name = dest_name.replace(\" \", \"_\") \n",
    "                output = f\"\\\"{iata_source}\\\",\\\"{wiki_name}\\\",\\\"{dest_name}\\\",\\\"{airline}\\\",\\\"{isSeasonal}\\\"\\n\" #final output to append to the file\n",
    "                file.write(output)#write file\n",
    "            elif ((child.name == \"b\") and (child.text == \"Seasonal:\")):\n",
    "                isSeasonal = 1 #get seasonal to be 1 for future destinations\n",
    "    file.close() #close\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair for CJJ\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Cheongju_International_Airport&oldid=1061569779\"\n",
    "jump_to_table(\"CJJ\",link=found_link,path_write=file_append_path, match=\"destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b10c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair for GAU\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Lokpriya_Gopinath_Bordoloi_International_Airport&oldid=1059628744\"\n",
    "jump_to_table(\"GAU\",link=found_link,path_write=file_append_path, match=\"destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSR did not exist then\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparing KUV https://en.wikipedia.org/w/index.php?title=Gunsan_Airport&oldid=1062262046\n",
    "\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Gunsan_Airport&oldid=1062262046\"\n",
    "jump_to_table(\"KUV\",link=found_link,path_write=file_append_path, match=\"destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparing KWJ https://en.wikipedia.org/w/index.php?title=Gunsan_Airport&oldid=1062262046\n",
    "\n",
    "found_link = \"https://en.wikipedia.org/w/index.php?title=Gwangju_Airport&oldid=1061570946\"\n",
    "jump_to_table(\"KWJ\",link=found_link,path_write=file_append_path, match=\"destinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparing KWJ -- no listed destination on those pages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8a822",
   "metadata": {},
   "source": [
    "# Part 4: Fixing formating, adding IATA dest column for the two dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b029b3",
   "metadata": {},
   "source": [
    "## Working on the pre2020 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65317c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/pre2020_routes.csv\"\n",
    "routes_data = pd.read_csv(\"./data/pre2020_routes.csv\")\n",
    "routes_data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6f436",
   "metadata": {},
   "source": [
    "#### fixing airline names with [] quotations, removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_airlines_list = []\n",
    "old_airlines_list = routes_data[\"airline\"]\n",
    "for airline in old_airlines_list:\n",
    "    airline = airline.split(\"[\")[0] #remove quotation\n",
    "    new_airlines_list.append(airline)\n",
    "routes_data[\"airline\"] = new_airlines_list\n",
    "routes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595eac28",
   "metadata": {},
   "source": [
    "#### attempting to get iata code using our existing database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3ec22",
   "metadata": {},
   "source": [
    "iterating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports =  pd.read_csv(\"./data/current_served_airports.csv\", on_bad_lines=\"skip\")\n",
    "#add iata_dest_source\n",
    "routes_data[\"iata_dest\"] = None \n",
    "for index, rows in routes_data.iterrows():\n",
    "    print(\"current row:\", index)\n",
    "    dest_wiki = rows[\"dest_wikipedia_name\"]\n",
    "    try:  #try to match to a iata code\n",
    "        match = airports[airports[\"wiki_name\"]==dest_wiki].iloc[0]\n",
    "        match = match[\"IATA\"]\n",
    "        routes_data[\"iata_dest\"][index] = match\n",
    "    except:\n",
    "        routes_data[\"iata_dest\"][index] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c125e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_data.to_csv(\"./data/pre2020_routes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_data = pd.read_csv(\"./data/pre2020_routes.csv\")\n",
    "routes_data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c8b2e5",
   "metadata": {},
   "source": [
    "Counting the number of destinations without iata information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_dest_Data = routes_data[routes_data[\"iata_dest\"].isnull()]\n",
    "print(len(none_dest_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e95cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_dest_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88e442",
   "metadata": {},
   "source": [
    "This is far too many missing iata codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the set of wikipedia\n",
    "missing_wikinames = none_dest_Data[\"dest_wikipedia_name\"].unique()\n",
    "print(len(missing_wikinames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe63d4",
   "metadata": {},
   "source": [
    "### create a new database of all airports (including past airports) from the current_served airports.csv data\n",
    "\n",
    "Use a set of functions（inspired from part 2) to get coordinate and iata data from dest_wikipedia_name. We add to the current served airports database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redirectCheck(wiki_name):\n",
    "    url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&action=raw\"\n",
    "    response = requests.get(url)\n",
    "    #find the text between\n",
    "    text = response.text\n",
    "\n",
    "    #check for redirect\n",
    "    check_text = text.split(\"[[\")[0] #get section between [[\n",
    "    check_text = check_text.lower()\n",
    "    #if the text is clearly too long (>10 lines, there is clearly no redirect)\n",
    "    lines = text.splitlines()\n",
    "    number_of_lines = len(lines)\n",
    "    if number_of_lines > 10:\n",
    "        return wiki_name\n",
    "\n",
    "    if (\"redirect\" in check_text):\n",
    "        #get the text in between [[]]\n",
    "        redirect = text.split(\"]]\")[0]\n",
    "        #if the text does not contain a key #, we reject\n",
    "        if \"#\" not in check_text:\n",
    "            return wiki_name\n",
    "        redirect = redirect.split(\"[[\")[1]\n",
    "        redirect = redirect.replace(\" \", \"_\") #replace spaces\n",
    "        print(\"redirect found:\", redirect)\n",
    "        return redirect\n",
    "    else:\n",
    "        return wiki_name #return the same name back\n",
    "\n",
    "def getRow(text, key): #help function to text a key from = of the first rpws\n",
    "    try:\n",
    "        regex = f\"{key}\"+'.*?='\n",
    "        match = re.findall(rf'{regex}', text)[0] #find the first indstance\n",
    "        \n",
    "        start = text.find(match) #find the starting index, by matching the re pattern iata*=\n",
    "        start += len(match) #do not include iata\n",
    "        \n",
    "        end = text.find(\"\\n\", start) #starting from the end, find the starting index\n",
    "        code = text[start:end]\n",
    "        code = code.split(\"<\")[0]#get rid of ref tags\n",
    "        code = code.strip()\n",
    "        return code\n",
    "    except:\n",
    "        #check for redirect\n",
    "        check_text = text.split(\"[[\")[0] #get section between [[\n",
    "        check_text = check_text.lower()\n",
    "        if (\"redirect\" in check_text):\n",
    "            #get the text in between [[]]\n",
    "            redirect = text.split(\"]]\")[0]\n",
    "            redirect = redirect.split(\"[[\")[1]\n",
    "            redirect = redirect.replace(\" \", \"_\") #replace spaces\n",
    "            #get text from redirect\n",
    "            url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&action=raw\"\n",
    "            response = requests.get(url)\n",
    "            #find the text between\n",
    "            text = response.text\n",
    "            return getRow(text, key)\n",
    "        return \"\" #return empty string if nothing is found\n",
    "\n",
    "#function to convert DMS coordinates on wiki to decimal ones\n",
    "def dms_to_decimal(degrees, minutes, seconds, direction):\n",
    "    dd = float(degrees) + float(minutes) / 60 + float(seconds) / 3600\n",
    "    if direction.upper() in ['S', 'W']:\n",
    "        dd *= -1\n",
    "    return str(dd)\n",
    "\n",
    "def getIataFromWikiName(wiki_name):\n",
    "    url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&action=raw\"\n",
    "    response = requests.get(url)\n",
    "    #find the text between\n",
    "    text = response.text\n",
    "    \n",
    "    try:\n",
    "        match = re.findall(r'IATA.*?=', text)[0] #find the first indstance\n",
    "        start = text.find(match) #find the starting index, by matching the re pattern iata*=\n",
    "        start += len(match) #do not include iata\n",
    "        \n",
    "        end = text.find(\"\\n\", start) #starting from the end, find the starting index\n",
    "        iata_code = text[start:end]\n",
    "        iata_code = iata_code.split(\"<\")[0]#get rid of ref tags\n",
    "        iata_code = iata_code.strip()\n",
    "        return iata_code\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def getDetailsFromWikiName(wiki_name):\n",
    "    #check for redirects\n",
    "    wiki_name = redirectCheck(wiki_name)\n",
    "\n",
    "    url = f\"https://en.wikipedia.org/w/index.php?title={wiki_name}&action=raw\"\n",
    "    response = requests.get(url)\n",
    "    #find the text between\n",
    "    text = response.text\n",
    "\n",
    "    #intialize as empty strings\n",
    "    city = \"\"\n",
    "    country = \"\"\n",
    "    lat = \"\"\n",
    "    long = \"\"\n",
    "    iata = getIataFromWikiName(wiki_name)\n",
    "    try:\n",
    "        #process city data\n",
    "        city = getRow(text,\"city-served\")#city\n",
    "        if \"[[\" in city:\n",
    "            city = city.split(\"[[\")[1]\n",
    "        city = city.split(\"]]\")[0]\n",
    "        # process latitude, longtitude data\n",
    "        coor = getRow(text,\"coordinates\")\n",
    "        coor = coor.split(\"}}\")[0]\n",
    "        coor = coor.split(\"{{\")[1]\n",
    "        coor = coor.split(\"|\")\n",
    "        lat = dms_to_decimal(coor[1],coor[2],coor[3],coor[4]) #convert using function\n",
    "        long = dms_to_decimal(coor[5],coor[6],coor[7],coor[8])\n",
    "        #get country data, using wikipedia api using city\n",
    "        url2 = f\"https://en.wikipedia.org/w/index.php?title={city}&action=raw\"\n",
    "        response2 = requests.get(url2)\n",
    "        #find the text between\n",
    "        text2 = response2.text\n",
    "        country = getRow(text2,\"subdivision_name\")\n",
    "        #depending on the enclosing symbol\n",
    "        if \"[\" in country:\n",
    "            country = country.split(\"[[\")[1]#get between [[]]\n",
    "            country = country.split(\"]]\")[0]\n",
    "        elif \"{\" in country:\n",
    "            #get between (())\n",
    "            country = country.split(\"{{\")[1]#get between [[]]\n",
    "            country = country.split(\"}}\")[0]\n",
    "        if \"|\" in country: #now, check for |\n",
    "            tlist = country.split(\"|\")\n",
    "            country = tlist[len(tlist)-1]\n",
    "        return {\"IATA\": iata, \"wiki_name\": wiki_name, \"city\":city, \"country\":country, \"latitude\":lat, \"longitude\":long}\n",
    "    except:\n",
    "        return {\"IATA\": iata, \"wiki_name\": wiki_name, \"city\":city, \"country\":country, \"latitude\":lat, \"longitude\":long}\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b6e18",
   "metadata": {},
   "source": [
    "Checking repair on missing data (we really only care about IATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dd0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "getDetailsFromWikiName(\"Tajima_Airport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27ff19",
   "metadata": {},
   "source": [
    "iterating to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b55987",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = pd.read_csv(\"./data/current_served_airports.csv\")\n",
    "save_path = \"./data/all_airports.csv\"#define the save path\n",
    "print(len(ref_data))\n",
    "ref_data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a2431",
   "metadata": {},
   "source": [
    "creating a function to run in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(missing_wikinames, ref_data, start, end):\n",
    "    new_rows = []\n",
    "    for i in range(start, end):\n",
    "        wiki_name = missing_wikinames[i]\n",
    "        print(\"current count repaired:\",i, \"with name:\", wiki_name)\n",
    "        new_data = getDetailsFromWikiName(wiki_name)\n",
    "        \n",
    "\n",
    "        new_rows.append(new_data)# new row are already in the proper dictionary format\n",
    "    ref_data = pd.concat([ref_data, pd.DataFrame(new_rows)], ignore_index=True) #append rows\n",
    "    ref_data.to_csv(save_path, index =False)\n",
    "    new_rows = [] #reset the new data\n",
    "    return ref_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12866b3c",
   "metadata": {},
   "source": [
    "Run in chucks of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a82f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "while (i< len(missing_wikinames)):\n",
    "    end = i+20 #run in chunks\n",
    "    if end > len(missing_wikinames):\n",
    "        end = len(missing_wikinames)\n",
    "    print(\"partition:\", i,end)\n",
    "    ref_data = fill_missing(missing_wikinames, ref_data, i, end)\n",
    "    time.sleep(1.2)\n",
    "    #increment \n",
    "    i = end "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102f04e",
   "metadata": {},
   "source": [
    "save new airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ce9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ref_data))\n",
    "ref_data.to_csv(\"./data/all_airports.csv\", index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730308a",
   "metadata": {},
   "source": [
    "Note this new dataset has few iata code mapping to different wikinames (due to redirects or new airports with the same iata code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcb061",
   "metadata": {},
   "source": [
    "running again on the new dataset to get destination iata codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f892a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_data = pd.read_csv(\"./data/pre2020_routes.csv\")\n",
    "\n",
    "airports =  pd.read_csv(\"./data/all_airports.csv\", on_bad_lines=\"skip\")\n",
    "#add iata_dest_source\n",
    "routes_data[\"iata_dest\"] = None \n",
    "for index, rows in routes_data.iterrows():\n",
    "    print(\"current row:\", index)\n",
    "    dest_wiki = rows[\"dest_wikipedia_name\"]\n",
    "    try:  #try to match to a iata code\n",
    "        match = airports[airports[\"wiki_name\"]==dest_wiki].iloc[0]\n",
    "        match = match[\"IATA\"]\n",
    "        routes_data[\"iata_dest\"][index] = match\n",
    "    except:\n",
    "        routes_data[\"iata_dest\"][index] = None\n",
    "\n",
    "routes_data.to_csv(\"./data/pre2020_routes.csv\", index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485c191",
   "metadata": {},
   "source": [
    "Count missing iata codes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ebf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_dest_Data = routes_data[routes_data[\"iata_dest\"].isnull()]\n",
    "print(len(none_dest_Data))\n",
    "none_dest_Data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e24ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "getDetailsFromWikiName(\"Orlando_Melbourne_International_Airport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab96868",
   "metadata": {},
   "source": [
    "## Working on the pre2022 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_data = pd.read_csv(\"./data/pre2022_routes.csv\")\n",
    "\n",
    "airports =  pd.read_csv(\"./data/all_airports.csv\", on_bad_lines=\"skip\")\n",
    "#add iata_dest_source\n",
    "routes_data[\"iata_dest\"] = None \n",
    "for index, rows in routes_data.iterrows():\n",
    "    print(\"current row:\", index)\n",
    "    dest_wiki = rows[\"dest_wikipedia_name\"]\n",
    "    try:  #try to match to a iata code\n",
    "        match = airports[airports[\"wiki_name\"]==dest_wiki].iloc[0]\n",
    "        match = match[\"IATA\"]\n",
    "        routes_data[\"iata_dest\"][index] = match\n",
    "    except:\n",
    "        routes_data[\"iata_dest\"][index] = None\n",
    "\n",
    "routes_data.to_csv(\"./data/pre2022_routes.csv\", index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb79a4",
   "metadata": {},
   "source": [
    "checking iata codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2505c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_dest_Data = routes_data[routes_data[\"iata_dest\"].isnull()]\n",
    "print(len(none_dest_Data))\n",
    "none_dest_Data.head(n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
